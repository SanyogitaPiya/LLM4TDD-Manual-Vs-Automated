# LLM4TDD-Manual-Vs-Automated
This work highlights the promise of the LLM4TDD process, but revealed that the quality of code generated is dependent on the test cases used as prompts.
Therefore, this paper conducts an empirical study to investigate how the origin of the test cases impacts the LLM4TDD process.
In particular, we explore the tradeoffs between automated and manually generated test on the efficacy of the code produced by the LLM4TDD workflow


![image](https://github.com/user-attachments/assets/1803a73d-8af2-4b87-9ec7-d4434b307828)

We address the following research questions:

• RQ1: When manually creating tests, what is the best high
level test suite strategy?

• RQ2: How effective can automatically generated tests be
in the LLM4TDD workflow?

• RQ3: What are the trade offs between automated versus
manual tests within the LLM4TDD workflow?
